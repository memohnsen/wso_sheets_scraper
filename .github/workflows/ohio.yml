name: Ohio WSO Records Scraper

on:
  schedule:
    # Run daily at 2 AM UTC (9 PM EST / 10 PM EDT)
    - cron: '0 3 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run scraper
        env:
          # GOOGLE_SERVICE_ACCOUNT_JSON is optional for public sheets
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          python scraper_ohio.py \
            --wso "Ohio" \
            --sheet-url "https://docs.google.com/spreadsheets/d/1fX-Ft3PuLn8BCE2thhwPEXFTEUTN7yJGxWi7LMajAD8/view?gid=0#gid=0"

